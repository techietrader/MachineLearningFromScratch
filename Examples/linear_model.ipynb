{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Import Numpy & PyTorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.gradient_descent import compute_gradient\n",
    "from ML.scaling import normalizing_values\n",
    "from ML.linear_model import model\n",
    "from ML.loss_functions import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.../MachineLearningFromScratch/Dataset/boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PT</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.199997</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>396.899994</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.900002</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>396.899994</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.099998</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>392.829987</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.799999</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>394.630005</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.200001</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>396.899994</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.200001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM        AGE     DIS  RAD  TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.199997  4.0900    1  296   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.900002  4.9671    2  242   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.099998  4.9671    2  242   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.799999  6.0622    3  222   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.200001  6.0622    3  222   \n",
       "\n",
       "          PT           B  LSTAT         MV  \n",
       "0  15.300000  396.899994   4.98  24.000000  \n",
       "1  17.799999  396.899994   9.14  21.600000  \n",
       "2  17.799999  392.829987   4.03  34.700001  \n",
       "3  18.700001  394.630005   2.94  33.400002  \n",
       "4  18.700001  396.899994   5.33  36.200001  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalizing_values(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting arrays to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Random Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(1,X.shape[1], requires_grad= True).float()\n",
    "bias    = torch.randn(1, requires_grad= True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([506, 13])\n",
      "torch.Size([506, 1])\n",
      "torch.Size([1, 13])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "print (y.shape)\n",
    "\n",
    "\n",
    "print (weights.shape)\n",
    "print (bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "LR = 1e-2\n",
    "CALLBACK_VALUE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 is 629.9680786132812\n",
      "Loss at epoch 1 is 608.3256225585938\n",
      "Loss at epoch 2 is 587.5414428710938\n",
      "Loss at epoch 3 is 567.581787109375\n",
      "Loss at epoch 4 is 548.4141845703125\n",
      "Loss at epoch 5 is 530.0064086914062\n",
      "Loss at epoch 6 is 512.3292236328125\n",
      "Loss at epoch 7 is 495.3531494140625\n",
      "Loss at epoch 8 is 479.0506286621094\n",
      "Loss at epoch 9 is 463.39471435546875\n",
      "Loss at epoch 10 is 448.3597106933594\n",
      "Loss at epoch 11 is 433.9212951660156\n",
      "Loss at epoch 12 is 420.0555114746094\n",
      "Loss at epoch 13 is 406.7398376464844\n",
      "Loss at epoch 14 is 393.9521789550781\n",
      "Loss at epoch 15 is 381.67218017578125\n",
      "Loss at epoch 16 is 369.8789367675781\n",
      "Loss at epoch 17 is 358.5537109375\n",
      "Loss at epoch 18 is 347.6775817871094\n",
      "Loss at epoch 19 is 337.2331848144531\n",
      "Loss at epoch 20 is 327.20269775390625\n",
      "Loss at epoch 21 is 317.5703125\n",
      "Loss at epoch 22 is 308.3201904296875\n",
      "Loss at epoch 23 is 299.4367980957031\n",
      "Loss at epoch 24 is 290.90570068359375\n",
      "Loss at epoch 25 is 282.713134765625\n",
      "Loss at epoch 26 is 274.8456115722656\n",
      "Loss at epoch 27 is 267.2900695800781\n",
      "Loss at epoch 28 is 260.0343017578125\n",
      "Loss at epoch 29 is 253.06639099121094\n",
      "Loss at epoch 30 is 246.37486267089844\n",
      "Loss at epoch 31 is 239.94873046875\n",
      "Loss at epoch 32 is 233.77749633789062\n",
      "Loss at epoch 33 is 227.85105895996094\n",
      "Loss at epoch 34 is 222.1597900390625\n",
      "Loss at epoch 35 is 216.6942138671875\n",
      "Loss at epoch 36 is 211.44541931152344\n",
      "Loss at epoch 37 is 206.4048614501953\n",
      "Loss at epoch 38 is 201.56423950195312\n",
      "Loss at epoch 39 is 196.9157257080078\n",
      "Loss at epoch 40 is 192.45150756835938\n",
      "Loss at epoch 41 is 188.16444396972656\n",
      "Loss at epoch 42 is 184.04737854003906\n",
      "Loss at epoch 43 is 180.0936279296875\n",
      "Loss at epoch 44 is 176.29673767089844\n",
      "Loss at epoch 45 is 172.65040588378906\n",
      "Loss at epoch 46 is 169.14874267578125\n",
      "Loss at epoch 47 is 165.7859649658203\n",
      "Loss at epoch 48 is 162.55662536621094\n",
      "Loss at epoch 49 is 159.4553985595703\n",
      "Loss at epoch 50 is 156.47714233398438\n",
      "Loss at epoch 51 is 153.61705017089844\n",
      "Loss at epoch 52 is 150.87030029296875\n",
      "Loss at epoch 53 is 148.23260498046875\n",
      "Loss at epoch 54 is 145.69956970214844\n",
      "Loss at epoch 55 is 143.26695251464844\n",
      "Loss at epoch 56 is 140.93080139160156\n",
      "Loss at epoch 57 is 138.6873779296875\n",
      "Loss at epoch 58 is 136.5329132080078\n",
      "Loss at epoch 59 is 134.46400451660156\n",
      "Loss at epoch 60 is 132.47702026367188\n",
      "Loss at epoch 61 is 130.5688934326172\n",
      "Loss at epoch 62 is 128.7364501953125\n",
      "Loss at epoch 63 is 126.97671508789062\n",
      "Loss at epoch 64 is 125.28679656982422\n",
      "Loss at epoch 65 is 123.66387176513672\n",
      "Loss at epoch 66 is 122.10533142089844\n",
      "Loss at epoch 67 is 120.6086196899414\n",
      "Loss at epoch 68 is 119.17127227783203\n",
      "Loss at epoch 69 is 117.79095458984375\n",
      "Loss at epoch 70 is 116.46532440185547\n",
      "Loss at epoch 71 is 115.19234466552734\n",
      "Loss at epoch 72 is 113.96979522705078\n",
      "Loss at epoch 73 is 112.7957763671875\n",
      "Loss at epoch 74 is 111.66828918457031\n",
      "Loss at epoch 75 is 110.5855484008789\n",
      "Loss at epoch 76 is 109.54576110839844\n",
      "Loss at epoch 77 is 108.54722595214844\n",
      "Loss at epoch 78 is 107.58824920654297\n",
      "Loss at epoch 79 is 106.66734313964844\n",
      "Loss at epoch 80 is 105.78296661376953\n",
      "Loss at epoch 81 is 104.93365478515625\n",
      "Loss at epoch 82 is 104.11800384521484\n",
      "Loss at epoch 83 is 103.33470916748047\n",
      "Loss at epoch 84 is 102.58255004882812\n",
      "Loss at epoch 85 is 101.86015319824219\n",
      "Loss at epoch 86 is 101.16641998291016\n",
      "Loss at epoch 87 is 100.50019836425781\n",
      "Loss at epoch 88 is 99.86040496826172\n",
      "Loss at epoch 89 is 99.24601745605469\n",
      "Loss at epoch 90 is 98.6559066772461\n",
      "Loss at epoch 91 is 98.08930969238281\n",
      "Loss at epoch 92 is 97.54512023925781\n",
      "Loss at epoch 93 is 97.02252960205078\n",
      "Loss at epoch 94 is 96.5206527709961\n",
      "Loss at epoch 95 is 96.0386962890625\n",
      "Loss at epoch 96 is 95.57582092285156\n",
      "Loss at epoch 97 is 95.13131713867188\n",
      "Loss at epoch 98 is 94.70446014404297\n",
      "Loss at epoch 99 is 94.29449462890625\n",
      "Loss at epoch 100 is 93.90081787109375\n",
      "Loss at epoch 101 is 93.52272033691406\n",
      "Loss at epoch 102 is 93.1596450805664\n",
      "Loss at epoch 103 is 92.8109359741211\n",
      "Loss at epoch 104 is 92.47608947753906\n",
      "Loss at epoch 105 is 92.15450286865234\n",
      "Loss at epoch 106 is 91.84566497802734\n",
      "Loss at epoch 107 is 91.54911041259766\n",
      "Loss at epoch 108 is 91.2642593383789\n",
      "Loss at epoch 109 is 90.99073028564453\n",
      "Loss at epoch 110 is 90.72801208496094\n",
      "Loss at epoch 111 is 90.47573852539062\n",
      "Loss at epoch 112 is 90.23347473144531\n",
      "Loss at epoch 113 is 90.00082397460938\n",
      "Loss at epoch 114 is 89.77735137939453\n",
      "Loss at epoch 115 is 89.56277465820312\n",
      "Loss at epoch 116 is 89.35669708251953\n",
      "Loss at epoch 117 is 89.15878295898438\n",
      "Loss at epoch 118 is 88.9687271118164\n",
      "Loss at epoch 119 is 88.78617858886719\n",
      "Loss at epoch 120 is 88.61085510253906\n",
      "Loss at epoch 121 is 88.44254302978516\n",
      "Loss at epoch 122 is 88.28087615966797\n",
      "Loss at epoch 123 is 88.12557983398438\n",
      "Loss at epoch 124 is 87.97648620605469\n",
      "Loss at epoch 125 is 87.83325958251953\n",
      "Loss at epoch 126 is 87.69573974609375\n",
      "Loss at epoch 127 is 87.56364440917969\n",
      "Loss at epoch 128 is 87.43682098388672\n",
      "Loss at epoch 129 is 87.31500244140625\n",
      "Loss at epoch 130 is 87.1980209350586\n",
      "Loss at epoch 131 is 87.08563232421875\n",
      "Loss at epoch 132 is 86.97774505615234\n",
      "Loss at epoch 133 is 86.87407684326172\n",
      "Loss didnot change with significant margin. Loss is 86.7745590209961\n"
     ]
    }
   ],
   "source": [
    "loss , weights, bias = compute_gradient(X,y,weights,bias, epochs=EPOCHS, callback_value=CALLBACK_VALUE, lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_Loss is 86.7745590209961\n",
      "\n",
      "\n",
      "Final_weights are tensor([[ 0.2623,  0.2336, -2.1791,  0.7839,  0.7022, -0.0393,  0.4102, -2.1613,\n",
      "          0.0291, -0.1526,  0.7036,  0.9817,  0.9376]], requires_grad=True)\n",
      "\n",
      "\n",
      "Final_bias is tensor([20.9566], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print ('Final_Loss is {}'.format(loss))\n",
    "print ('\\n')\n",
    "print ('Final_weights are {}'.format(weights))\n",
    "print ('\\n')\n",
    "print ('Final_bias is {}'.format(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
